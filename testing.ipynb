{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ola/miniforge3/envs/pycaret_env/lib/python3.8/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import preprocess_all\n",
    "from lightfm_functions import (\n",
    "    get_clean_dataframes,\n",
    "    create_lightfm_dataset,\n",
    "    train_lightfm_model,\n",
    "    train_test_split_data,\n",
    "    hyperparameters_tuning,\n",
    ")\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(min_count_author, min_count_user_ints, path=\"data/\", to_save=True):\n",
    "    interactions_df = pd.read_csv(\n",
    "        path + \"interactions.csv\", sep=\";\", error_bad_lines=False, encoding=\"latin-1\"\n",
    "    )\n",
    "\n",
    "    users_df = pd.read_csv(\n",
    "        path + \"users.csv\", sep=\";\", encoding=\"latin-1\", error_bad_lines=False\n",
    "    )\n",
    "    items_df = pd.read_csv(\n",
    "        path + \"items.csv\", sep=\";\", encoding=\"latin-1\", error_bad_lines=False\n",
    "    )\n",
    "\n",
    "    interactions_df, items_df, users_df = preprocess_all(\n",
    "        interactions_df, items_df, users_df, min_count_author, min_count_user_ints\n",
    "    )\n",
    "\n",
    "    if to_save:\n",
    "        interactions_df.to_csv(path + \"interactions_clean.csv\", index=False)\n",
    "        items_df.to_csv(path + \"items_clean.csv\", index=False)\n",
    "        users_df.to_csv(path + \"users_clean.csv\", index=False)\n",
    "\n",
    "    return interactions_df, items_df, users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean datasets are imported\n",
      "(192228, 3) (49437, 3) (13787, 6)\n",
      "LightFM dataset is created\n"
     ]
    }
   ],
   "source": [
    "# interactions_df, items_df, users_df = get_dataframes(5, 5)\n",
    "# print('Datasets are saved')\n",
    "\n",
    "interactions_df, items_df, users_df = get_clean_dataframes()\n",
    "print(\"Clean datasets are imported\")\n",
    "print(interactions_df.shape, users_df.shape, items_df.shape)\n",
    "(\n",
    "    dataset,\n",
    "    user_ids_buffered,\n",
    "    item_ids_buffered,\n",
    "    interactions,\n",
    "    weights,\n",
    ") = create_lightfm_dataset(interactions_df)\n",
    "print(\"LightFM dataset is created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights, test_weights = train_test_split_data(weights, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1:\n",
      "\n",
      "Hyperparameters: {'no_components': 50, 'learning_schedule': 'adagrad', 'loss': 'warp', 'learning_rate': 0.2, 'max_sampled': 12, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.85417, Test AUC 0.56293\n",
      "Train Precision@10 0.00384, Test Precision@10 0.00105\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #2:\n",
      "\n",
      "Hyperparameters: {'no_components': 98, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.02, 'max_sampled': 14, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.95202, Test AUC 0.62347\n",
      "Train Precision@10 0.08574, Test Precision@10 0.00491\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #3:\n",
      "\n",
      "Hyperparameters: {'no_components': 19, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 0.1, 'max_sampled': 10, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.95702, Test AUC 0.60264\n",
      "Train Precision@10 0.07619, Test Precision@10 0.00454\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #4:\n",
      "\n",
      "Hyperparameters: {'no_components': 94, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.04, 'max_sampled': 9, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.98745, Test AUC 0.76911\n",
      "Train Precision@10 0.07855, Test Precision@10 0.00615\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #5:\n",
      "\n",
      "Hyperparameters: {'no_components': 64, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.09, 'max_sampled': 10, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.93584, Test AUC 0.77207\n",
      "Train Precision@10 0.03281, Test Precision@10 0.00579\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #6:\n",
      "\n",
      "Hyperparameters: {'no_components': 51, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.15, 'max_sampled': 10, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.95591, Test AUC 0.62487\n",
      "Train Precision@10 0.08431, Test Precision@10 0.00473\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #7:\n",
      "\n",
      "Hyperparameters: {'no_components': 103, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.13, 'max_sampled': 9, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.98034, Test AUC 0.77191\n",
      "Train Precision@10 0.06813, Test Precision@10 0.00617\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #8:\n",
      "\n",
      "Hyperparameters: {'no_components': 32, 'learning_schedule': 'adagrad', 'loss': 'warp', 'learning_rate': 0.13, 'max_sampled': 11, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.99456, Test AUC 0.65824\n",
      "Train Precision@10 0.06967, Test Precision@10 0.00224\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #9:\n",
      "\n",
      "Hyperparameters: {'no_components': 39, 'learning_schedule': 'adagrad', 'loss': 'warp', 'learning_rate': 0.15, 'max_sampled': 8, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.98762, Test AUC 0.62130\n",
      "Train Precision@10 0.02108, Test Precision@10 0.00154\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #10:\n",
      "\n",
      "Hyperparameters: {'no_components': 126, 'learning_schedule': 'adagrad', 'loss': 'warp', 'learning_rate': 0.14, 'max_sampled': 13, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.99760, Test AUC 0.61501\n",
      "Train Precision@10 0.09549, Test Precision@10 0.00193\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #11:\n",
      "\n",
      "Hyperparameters: {'no_components': 117, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 0.01, 'max_sampled': 9, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.53701, Test AUC 0.53311\n",
      "Train Precision@10 0.00348, Test Precision@10 0.00155\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #12:\n",
      "\n",
      "Hyperparameters: {'no_components': 113, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 0.05, 'max_sampled': 5, 'random_state': [42]}\n",
      "\n",
      "Train AUC 0.60520, Test AUC 0.54895\n",
      "Train Precision@10 0.00947, Test Precision@10 0.00115\n",
      "\n",
      "========================================\n",
      "\n",
      "Model #13:\n",
      "\n",
      "Hyperparameters: {'no_components': 110, 'learning_schedule': 'adagrad', 'loss': 'warp', 'learning_rate': 0.08, 'max_sampled': 9, 'random_state': [42]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparameters_tuning(train_weights, test_weights, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is trained and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# If you selected different hyperparameters then change train_lightfm_model function\n",
    "\n",
    "model = train_lightfm_model(weights, True)\n",
    "print(\"The model is trained and saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
